<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>L'Hypoth√®se de Repr√©sentation Platonique dans un petit monde : le Morpion</title>

    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    
    <!-- Favicon -->
    <link rel="icon" type="image/svg+xml" href="../assets/logo.svg">
    <link rel="alternate icon" href="../assets/favicon.ico">
    <link rel="mask-icon" href="../assets/logo.svg" color="#0e7862">
    <script src="https://unpkg.com/react@17/umd/react.development.js"></script>
    <script src="https://unpkg.com/react-dom@17/umd/react-dom.development.js"></script>
    <script src="https://unpkg.com/babel-standalone@6/babel.min.js"></script>
    <script src="https://unpkg.com/recharts/umd/Recharts.js"></script>
    <style>
        body {
            font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            max-width: 900px;
            margin: 0 auto;
            background-color: #f5f9ff;
        }
        .content-margin-container {
            display: flex;
            width: 100%;
            justify-content: center;
            align-items: flex-start;
        }
        .main-content-block {
            width: 130%;
            max-width: 1100px;
            background-color: #fff;
            border-left: 1px solid #DDD;
            border-right: 1px solid #DDD;
            padding: 16px;
        }
        .margin-left-block, .margin-right-block {
            font-size: 14px;
            width: 10%;
            max-width: 100px;
            position: relative;
            margin-left: 5px;
            text-align: left;
            padding: 5px;
        }
        .margin-left-block {
            position: sticky;
            top: 20px;
        }
        h1 {
            font-size: 32px;
            font-family: 'Courier New', Courier, monospace;
            margin-top: 4px;
            margin-bottom: 10px;
            text-align: center;
        }
        h2 {
            font-size: 18px;
            color: #666;
        }
        a {
            color: #0e7862;
            text-decoration: none;
        }
        a:hover {
            color: #24b597;
        }
        .header {
            font-weight: 300;
            font-size: 17px;
            text-align: center;
        }
        img {
            max-width: 100%;
            height: auto;
            display: block;
            margin: auto;
        }
        #languageSelector {
            position: absolute;
            top: 10px;
            right: 10px;
        }
        .profile-image {
            width: 200px;
            height: 200px;
            border-radius: 50%;
            object-fit: cover;
            margin: 20px auto;
        }
        .side-menu {
            list-style-type: none;
            padding: 0;
        }
        .side-menu li {
            margin-bottom: 10px;
        }
    </style>
</head>
<body>
    <select id="languageSelector" onchange="changeLanguage(this.value)">
        <option value="en">English</option>
        <option value="fr">Fran√ßais</option>
    </select>

    <div class="content-margin-container">
        <div class="margin-left-block">
            <ul class="side-menu">
                <li><a href="../index.html" data-translate="menu_home">Accueil</a></li>
                <li><a href="../projets.html" data-translate="menu_projects">Projets</a></li>
                <li><a href="../blog.html" data-translate="menu_blog">Blog</a></li>
                <li><a href="https://github.com/l-pommeret" data-translate="github">GitHub</a></li>
                <li><a href="../perso.html" data-translate="projets_perso">Projets personnels</a></li>
            </ul>
        </div>
        <div class="main-content-block">
            <h1>L'Hypoth√®se de Repr√©sentation Platonique dans un petit monde : le Morpion</h1>
            <p class="header">Par Luc Pommeret</p>
            
            <div class="abstract">
                <h2>R√©sum√©</h2>
                <p>Ce projet s'inspire de l'article de juin 2024 de Philip Isola et ses √©tudiants : Platonic Representation Hypothesis. L'id√©e centrale est que les mod√®les entra√Æn√©s sur diff√©rents types de donn√©es (image, audio, texte) convergent vers la m√™me repr√©sentation dans l'espace latent. Le code pour l'entra√Ænement des transformers est bas√© sur le travail d'Andrej Karpathy (nanoGPT). Dans ce projet, nous testons cette hypoth√®se sur un monde tr√®s simple : le Morpion. Nous entra√Ænons deux transformers avec la m√™me architecture et le m√™me nombre de param√®tres sur : 1) des images PNG de parties, 2) des parties en notation textuelle standard.</p>
                <p>Tout le code est disponible sur GitHub √† cette adresse : <a href="https://github.com/l-pommeret/platonic_representation">https://github.com/l-pommeret/platonic_representation</a></p>
            </div>

            <h2>Introduction</h2>
            <p>Les LLMs sont des mod√®les dont la performance sur le langage humain n'est plus √† d√©montrer. Fond√©e sur l'architecture <i>transformer</i>, leurs capacit√©s hors-norme semblent parfois nous √©chapper, si bien qu'on ne comprend pas toujours comment le mod√®le inf√®re ce qu'il inf√®re.</p>
            <p>Une hypoth√®se en particulier a attir√© notre attention, parce qu'elle semble faire la synth√®se de nombreuses observations √©parses que l'on a pu faire dans le domaine de l'interpr√©tabilit√© (ou explicabilit√©). Il s'agit de la PRH, ou <i>Platonic Representation Hypothesis</i>, qui postule que les mod√®les de <i>transformer</i> se forgent un mod√®le de repr√©sentation du monde durant l'entra√Ænement, r√©sultant de la recherche de simplicit√© que recherche naturellement un r√©seau de neurones qui apprend.</p>
            <p>La cons√©quence la plus surprenante de leur hypoth√®se est que des mod√®les entra√Æn√©s sur diff√©rents types de donn√©es (images, texte, sons, etc.) vont converger vers la m√™me repr√©sentation dans leur <i>espace latent</i>. Notre but ici sera d'√©tudier en profondeur un cas simple, tr√®s simple, celui du Morpion. Dans ce jeu, dont l'ensemble des parties peut √™tre g√©n√©r√© en quelques minutes par un ordinateur moderne, le monde est tr√®s simple, et ne n√©cessite pas une immense puissance de calcul, autre avantage dont nous pourrons tirer parti.</p>
            <p>Ici nous allons √©tudier les repr√©sentations de deux <i>transformers</i> : l'un est entra√Æn√© sur des images du jeu, et l'autre sur des s√©quences de coups sous forme de texte.</p>
            
            <img src="https://raw.githubusercontent.com/l-pommeret/platonic_representation/main/assets/txt_img.png" alt="Repr√©sentations textuelles et imag√©es du Morpion">
            
            <p>L'hypoth√®se principale que nous voulons tester est en somme si les deux repr√©sentations d'une m√™me partie de Morpion convergent.</p>
            <p>Pour pr√©parer le terrain et explorer d'autres aspects de l'interpr√©tation de l'architecture <i>transformer</i>, nous allons effectuer des tests √† l'aide d'autres techniques, √† commencer par le <i>sondage</i> (<i>probing</i>).</p>

            <h2>Comment repr√©senter une partie de Morpion ?</h2>
            <p>Le morpion, comme les √©checs ou les dames, est un jeu de plateau. Mais contrairement aux deux derniers, il est extr√™mement simple, ce qui permet la compl√©tude de l'analyse (on g√©n√®re toutes les parties possibles, et on analyse notre <i>transformer</i> avec toutes ces parties).</p>
            <p>Une mani√®re tr√®s simple, voire enfantine, de repr√©senter une partie de morpion est de la noter sous forme de dessin, c√¥te √† c√¥te, en montrant l'√©tat du plateau √† chaque trait. C'est le format que nous avons choisi pour les images, qui ont donc une taille 9x9.</p>
            
            <img src="https://raw.githubusercontent.com/l-pommeret/platonic_representation/main/assets/game.png" alt="Repr√©sentation d'une partie de Morpion">
            
            <p>Pour noter les parties de Morpion textuellement, nous avons choisi de noter les coups les uns √† la suite des autres, comme le format PGN aux √©checs, ce qui donne un historique de la partie.</p>
            <p>Le format du jeu de Morpion √©tant ce qu'il est, le nombre de coups ne peut exc√©der 9, ce qui est bien pratique pour la tok√©nisation, premi√®re √©tape de l'apprentissage.</p>
            <p>Voici les tok√©nisations respectives des images et des textes (que l'on trouve dans les fichiers <code>meta.pkl</code>) :</p>
            
            <pre>
{
"vocab_size": 4,
"itos": {"0": "b", "1": "n", "2": "g", "3": ";"},
"stoi": {"b": 0, "n": 1, "g": 2, ";": 3}
}
            </pre>
            
            <pre>
{
"vocab_size": 10,
"itos": {"0": ";", "1": " ", "2": "0", "3": "1", "4": "2", "5": "3", "6": "X", "7": "O", "8": "/", "9": "-"},
"stoi": {";": 0, " ": 1, "0": 2, "1": 3, "2": 4, "3": 5, "X": 6, "O": 7, "/": 8, "-": 9}
}
            </pre>
            
            <p>Les <i>stoi</i> et les <i>itos</i> ne sont pas grecs, mais un format de donn√©es qui permet de convertir les cha√Ænes de caract√®res (strings) en entiers naturels (integers), c'est-√†-dire string to integer ou plus simplement <i>stoi</i>, l'<i>itos</i> √©tant l'op√©ration r√©ciproque.</p>
            <p>La tok√©nisation des images repose sur le pixel, qui sera blanc, valeur 0 (repr√©sent√© par 'b'), si la case est satur√©e par un X, noire, valeur 1 (repr√©sent√© par 'n'), si la case est satur√©e par un O, et grise, valeur 2 (repr√©sent√© par 'g') si la case est vide. L'image est parcourue de mani√®re naturelle, ligne par ligne pour former une ligne au format <code>str</code> (string).</p>
            <p>Dans les deux cas, ";" est le token de d√©but, celui qui marque le d√©but de la s√©quence pour les images comme pour les textes.</p>

            <h2>Probing</h2>
            <p>Le <i>probing</i> (ou sondage) est une technique permettant de d√©tecter la pr√©sence de propri√©t√©s dans un r√©seau de neurones. C'est une technique qui a √©t√© abondamment utilis√©e depuis 2018 et l'article Manning et al. qui l'applique √† la d√©tection d'arbres syntaxiques dans un transformer entra√Æn√© sur un corpus de textes √©tiquet√©s.</p>
            <p>Ici, nous voulons utiliser le <i>probing</i> pour d√©tecter la pr√©sence ou non d'une repr√©sentation du plateau de morpion, couche par couche dans le <i>transformer</i>. L'id√©e est d'entra√Æner un classifieur lin√©aire case par case et couche par couche pour qu'il d√©tecte l'√©tat d'une case (X, O ou vide). La technique utilis√©e ici est une g√©n√©ralisation du SVM originel, appel√©e <i>OneVsRest</i>.</p>

            <h3>Qu'est-ce qu'un SVM lin√©aire ?</h3>
            <p>Le SVM (Support Vector Machine) lin√©aire est une technique d'apprentissage supervis√© utilis√©e pour la classification. Dans le cas binaire, l'objectif est de trouver un hyperplan qui s√©pare au mieux les deux classes de donn√©es. Dans le cas lin√©aire qui nous occupe, il s'agit donc de trouver l'hyperplan qui explique le mieux la s√©paration des donn√©es dans le r√©seau de neurones.</p>
            <p>Soit un ensemble de donn√©es d'entra√Ænement \(\{(x_i, y_i)\}_{i=1}^n\), o√π \(x_i \in \mathbb{R}^d\) sont les vecteurs de caract√©ristiques et \(y_i \in \{-1, +1\}\) sont les √©tiquettes de classe.</p>
            <p>L'hyperplan s√©parateur est d√©fini par l'√©quation :</p>
            <p>\[w^T x + b = 0\]</p>
            <p>o√π \(w \in \mathbb{R}^d\) est le vecteur normal √† l'hyperplan et \(b \in \mathbb{R}\) est le biais.</p>        

            

            <h4>Probl√®me d'optimisation</h4>
            <p>Le SVM cherche √† maximiser la marge entre l'hyperplan et les points les plus proches de chaque classe. Cela se traduit par le probl√®me d'optimisation suivant :</p>
            
            \[
            \begin{aligned}
            \min_{w,b} &\quad \frac{1}{2} \|w\|^2 \\
            \text{s.c.} &\quad y_i(w^T x_i + b) \geq 1, \quad i = 1, \ldots, n
            \end{aligned}
            \]
            
            <p>En utilisant les multiplicateurs de Lagrange, on obtient la formulation duale :</p>
            
            \[
            \begin{aligned}
            \max_{\alpha} &\quad \sum_{i=1}^n \alpha_i - \frac{1}{2} \sum_{i=1}^n \sum_{j=1}^n \alpha_i \alpha_j y_i y_j x_i^T x_j \\
            \text{s.c.} &\quad \sum_{i=1}^n \alpha_i y_i = 0 \\
            &\quad 0 \leq \alpha_i \leq C, \quad i = 1, \ldots, n
            \end{aligned}
            \]
            
            <p>o√π \(\alpha_i\) sont les multiplicateurs de Lagrange et C est un param√®tre de r√©gularisation.</p>
            <p>Une fois les \(\alpha_i\) optimaux trouv√©s, la fonction de d√©cision pour un nouveau point x est :</p>
            <p>\[f(x) = \text{sign}\left(\sum_{i=1}^n \alpha_i y_i x_i^T x + b\right)\]</p>
            <p>o√π b est calcul√© en utilisant les vecteurs de support (points pour lesquels \(\alpha_i > 0\)).</p>
        

            <h4>Extension multi-classe</h4>
            <p>Dans notre code, une approche <i>One-vs-Rest</i> est utilis√©e pour √©tendre le SVM binaire au cas multi-classe. Pour K classes, on entra√Æne K classifieurs binaires, chacun s√©parant une classe de toutes les autres.</p>

            <h3>Les r√©sultats couche par couche</h3>
            <p>Le transformer est une architecture assez complexe qui permet de multiples points de sonde. Nous avons donc voulu sonder les moindres recoins de celui-ci pour avoir une id√©e de la repr√©sentation du plateau de morpion √† chaque √©tape.</p>
            <p>Voici les r√©sultats en prenant la pr√©cision de l'√©valuation du SVM couche par couche pour le texte.</p>
            
            <img src="https://raw.githubusercontent.com/l-pommeret/platonic_representation/main/assets/txt_accuracy_across_probe_points.png" alt="Probing couche par couche pour le texte">
            
            <p>Nous pouvons observer que le transformer acquiert petit √† petit une repr√©sentation de l'√©tat du plateau de morpion, qui culmine lors de la normalisation post-attention et de la seconde couche du MLP.</p>
            <p>Pour le mod√®le entra√Æn√© sur les images, le r√©sultat est tr√®s diff√©rent, puisque la courbe reste quasiment plate tout du long du <i>transformer</i>.</p>
            
            <img src="https://raw.githubusercontent.com/l-pommeret/platonic_representation/main/assets/img_accuracy_across_probe_points.png" alt="Probing couche par couche pour les images">
            
            <p>On remarque que le mod√®le ne forge pas de repr√©sentation du plateau de Morpion, ce qui peut interroger. Pour r√©pondre √† cela, nous pouvons formuler l'hypoth√®se qu'√©tant donn√© que pour r√©soudre la t√¢che (pr√©dire le prochain token), il faut avoir une repr√©sentation sur laquelle se reposer √† au moins un moment, il n'y a pas besoin de se forger une repr√©sentation lorsqu'on a d√©j√† l'image en entr√©e, alors que c'est n√©cessaire lorsqu'on n'a que le texte.</p>
            <p>Nous pouvons √©galement nous int√©resser √† la repr√©sentation des cases (<i>positions</i>), qui montre des effets de sym√©trie et d'asym√©trie assez int√©ressants.</p>
            
            <img src="https://raw.githubusercontent.com/l-pommeret/platonic_representation/main/assets/txt_accuracy_across_positions_all_points.png" alt="Probing couche par couche pour le texte (positions)">
            
            <img src="https://raw.githubusercontent.com/l-pommeret/platonic_representation/main/assets/img_accuracy_across_positions_all_points.png" alt="Probing couche par couche pour les images (positions)">
            
            <p>Une observation g√©n√©rale est que tr√®s souvent, dans la plupart des couches des deux mod√®les, c'est la case du milieu (position 5) qui est la mieux repr√©sent√©e.</p>
            <p>Ensuite, nous pouvons observer de belles sym√©tries, surtout pour le texte, et certaines couches, qui montrent une repr√©sentation g√©om√©trique du plateau, qui √©volue en fonction de la couche. Par exemple, dans le mod√®le d'image, la couche de normalisation pr√©-attention avantage clairement la case centrale, tandis que plus on s'approche de la sortie, moins cette case du milieu est favoris√©e, au profit d'autres cases, comme si l'analyse effectuait un mouvement concentrique vers les bords du plateau.</p>

            <h2>La PRH se v√©rifie-t-elle ?</h2>

            <h3>Quelles m√©triques ?</h3>
            <p>Suivant la litt√©rature ant√©rieure, nous d√©finissons l'<i>alignement repr√©sentationnel</i> comme une mesure de la similarit√© des structures de similarit√© induites par deux repr√©sentations, c'est-√†-dire une m√©trique de similarit√© sur les noyaux. Nous donnons la d√©finition math√©matique de ces concepts ci-dessous :</p>
            <ul>
                <li>Une <strong>repr√©sentation</strong> est une fonction f : X ‚Üí ‚Ñù^n qui attribue un vecteur de caract√©ristiques √† chaque entr√©e dans un certain domaine de donn√©es X.</li>
                <li>Un <strong>noyau</strong>, K : X √ó X ‚Üí ‚Ñù, caract√©rise comment une repr√©sentation mesure la distance/similarit√© entre les points de donn√©es. K(x_i,x_j)=‚ü®f(x_i),f(x_j)‚ü©, o√π ‚ü®¬∑,¬∑‚ü© d√©signe le produit scalaire, x_i,x_j ‚àà X et K ‚àà ùí¶.</li>
                <li>Une <strong>m√©trique d'alignement de noyau</strong>, m : ùí¶ √ó ùí¶ ‚Üí ‚Ñù, mesure la similarit√© entre deux noyaux, c'est-√†-dire √† quel point la mesure de distance induite par une repr√©sentation est similaire √† celle induite par une autre. Les exemples incluent la Distance de Noyau Centr√©e (CKA), SVCCA, et les m√©triques des plus proches voisins.</li>
            </ul>

            <h3>M√©triques d'alignement</h3>

            <h4>Cycle KNN (K plus proches voisins cycliques)</h4>
            <p><strong>D√©finition math√©matique</strong><br>
            Soient A et B deux ensembles de vecteurs de caract√©ristiques, chacun de taille N. Pour un k donn√© :</p>
            <ol>
                <li>Calculer les k-NN dans A : Pour chaque point dans A, trouver ses k plus proches voisins dans A.</li>
                <li>Mapper ces voisins vers B.</li>
                <li>Calculer les k-NN dans B pour ces points mapp√©s.</li>
                <li>V√©rifier si le point original dans A est parmi ces voisins.</li>
            </ol>
            <p>La m√©trique est la fraction de points qui "survivent" √† ce cycle.</p>
            <p><strong>Formule</strong></p>
            \[
            \text{Cycle\_KNN}(A, B) = \frac{1}{N} \sum_{i=1}^N \mathbb{I}(a_i \in \text{kNN}_B(\text{kNN}_A(a_i)))
            \]
            <p>o√π \(\mathbb{I}\) est la fonction indicatrice, et \(\text{kNN}_X(y)\) renvoie les k plus proches voisins de y dans X.</p>
        
            <p><strong>Interpr√©tation</strong></p>
            <ul>
                <li>Plage : [0, 1]</li>
                <li>Des valeurs plus √©lev√©es indiquent un meilleur alignement entre les deux espaces de caract√©ristiques.</li>
                <li>Une valeur de 1 signifie une parfaite consistance cyclique : la structure de voisinage est parfaitement pr√©serv√©e lors du mapping de A vers B et retour.</li>
                <li>Des valeurs plus basses sugg√®rent que la structure locale n'est pas bien pr√©serv√©e entre les deux espaces.</li>
            </ul>

            <h4>KNN mutuel (K plus proches voisins mutuels)</h4>
            <p><strong>D√©finition math√©matique</strong><br>
            Pour chaque point dans A, v√©rifier s'il est parmi les k-plus proches voisins de son point correspondant dans B, et vice versa.</p>
            <p><strong>Formule</strong></p>
            \[
            \text{Mutual\_KNN}(A, B) = \frac{1}{N} \sum_{i=1}^N \mathbb{I}(a_i \in \text{kNN}_B(b_i) \text{ ET } b_i \in \text{kNN}_A(a_i))
            \]
            <p>o√π \(\mathbb{I}\) est la fonction indicatrice, et \(\text{kNN}_X(y)\) renvoie les k plus proches voisins de y dans X.</p>
        
            <p><strong>Interpr√©tation</strong></p>
            <ul>
                <li>Plage : [0, 1]</li>
                <li>Des valeurs plus √©lev√©es indiquent une meilleure pr√©servation mutuelle du voisinage entre les deux espaces.</li>
                <li>Une valeur de 1 signifie que tous les points sont des k-plus proches voisins mutuels dans les deux espaces.</li>
                <li>Des valeurs plus basses sugg√®rent que les structures de voisinage dans A et B sont diff√©rentes.</li>
            </ul>

            <h4>CKA (Alignement de Noyau Centr√©)</h4>
            <p><strong>D√©finition math√©matique</strong><br>
            CKA mesure la similarit√© entre deux noyaux apr√®s centrage.</p>
            <p><strong>Formule</strong></p>
            \[
            \text{CKA}(K, L) = \frac{\langle K_c, L_c \rangle_F}{\|K_c\|_F \|L_c\|_F}
            \]
            <p>o√π \(K_c\) et \(L_c\) sont des matrices de noyau centr√©es, \(\langle \cdot,\cdot \rangle_F\) est le produit scalaire de Frobenius, et \(\|\cdot\|_F\) est la norme de Frobenius.</p>
        
            <p><strong>Interpr√©tation</strong></p>
            <ul>
                <li>Plage : [0, 1]</li>
                <li>Des valeurs plus √©lev√©es indiquent une plus grande similarit√© entre les matrices de noyau.</li>
                <li>Une valeur de 1 sugg√®re que les deux noyaux capturent des relations identiques entre les points de donn√©es.</li>
                <li>Des valeurs plus basses indiquent que les noyaux capturent des relations diff√©rentes.</li>
                <li>CKA est invariant aux transformations orthogonales et √† la mise √† l'√©chelle isotrope.</li>
            </ul>

            <h4>SVCCA (Analyse de Corr√©lation Canonique des Vecteurs Singuliers)</h4>
            <p><strong>D√©finition math√©matique</strong></p>
            <ol>
                <li>Effectuer la SVD sur les deux matrices de caract√©ristiques : A = U_A Œ£_A V_A^T, B = U_B Œ£_B V_B^T</li>
                <li>Prendre les d premiers vecteurs singuliers : ≈®_A, ≈®_B</li>
                <li>Effectuer la CCA sur ces matrices tronqu√©es</li>
            </ol>
            <p><strong>Formule</strong></p>
    \[
    \text{SVCCA}(A, B) = \frac{1}{d} \sum_{i=1}^d \rho_i
    \]
    <p>o√π \(\rho_i\) sont les corr√©lations canoniques entre \(\tilde{U}_A\) et \(\tilde{U}_B\).</p>
    
    <p>Les √©tapes pour calculer SVCCA sont :</p>
    <ol>
        <li>Effectuer la SVD sur les deux matrices de caract√©ristiques : 
            \[A = U_A \Sigma_A V_A^T, \quad B = U_B \Sigma_B V_B^T\]
        </li>
        <li>Prendre les d premiers vecteurs singuliers : \(\tilde{U}_A, \tilde{U}_B\)</li>
        <li>Effectuer la CCA sur ces matrices tronqu√©es</li>
    </ol>
            <p><strong>Interpr√©tation</strong></p>
            <ul>
                <li>Plage : [0, 1]</li>
                <li>Des valeurs plus √©lev√©es indiquent une corr√©lation plus forte entre les composantes principales des deux espaces de caract√©ristiques.</li>
                <li>Une valeur proche de 1 sugg√®re que les principales directions de variation dans les deux espaces sont fortement align√©es.</li>
                <li>Des valeurs plus basses indiquent que les composantes principales des deux espaces capturent diff√©rents aspects des donn√©es.</li>
                <li>SVCCA est moins sensible au bruit compar√© √† la simple CCA, en raison de l'√©tape initiale de SVD.</li>
            </ul>

            <h3>Conclusion</h3>
            <p>Ces m√©triques fournissent diff√©rentes perspectives sur l'alignement entre deux ensembles de caract√©ristiques :</p>
            <ul>
                <li>Cycle KNN et Mutual KNN sont plus sensibles aux structures locales et peuvent √™tre utiles pour d√©tecter des alignements fins.</li>
                <li>CKA est plus robuste et capture des similarit√©s globales, mais peut manquer des d√©tails fins.</li>
                <li>SVCCA est utile pour comparer les principales directions de variation, mais peut ignorer les caract√©ristiques moins importantes.</li>
            </ul>
            <p>En pratique, il est souvent b√©n√©fique d'utiliser plusieurs de ces m√©triques ensemble pour obtenir une image plus compl√®te de l'alignement entre deux ensembles de caract√©ristiques.</p>

            <h3>Les r√©sultats</h3>
            
            <img src="https://raw.githubusercontent.com/l-pommeret/platonic_representation/main/assets/metrics_comparison.png" alt="Diff√©rentes m√©triques pour comparer la distance des repr√©sentations entre les deux mod√®les">
            
            <h2>Bibliographie</h2>
            <ol>
                <li>Huh, M., Cheung, B., Wang, T., & Isola, P. (2024). The Platonic Representation Hypothesis. <i>arXiv preprint</i>.</li>
                <li>Kornblith, S., Norouzi, M., Lee, H., & Hinton, G. (2019). Similarity of neural network representations revisited. In <i>International Conference on Machine Learning</i> (pp. 3519-3529). PMLR.</li>
                <li>Raghu, M., Gilmer, J., Yosinski, J., & Sohl-Dickstein, J. (2017). SVCCA: Singular vector canonical correlation analysis for deep learning dynamics and interpretability. In <i>Advances in Neural Information Processing Systems</i> (pp. 6076-6085).</li>
                <li>Karvonen, A. (2024). Emergent World Models and Latent Variable Estimation in Chess-Playing Language Models. <i>arXiv preprint</i>.</li>
            </ol>
        </div>
        <div class="margin-right-block"></div>
    </div>

    <script>
        const translations = {
            'fr': {
                'menu_home': 'Accueil',
                'menu_projects': 'Projets',
                'menu_blog': 'Blog',
                'github': 'GitHub'
            },
            'en': {
                'menu_home': 'Home',
                'menu_projects': 'Projects',
                'menu_blog': 'Blog',
                'github': 'GitHub'
            }
        };

        function changeLanguage(lang) {
            document.documentElement.lang = lang;
            document.querySelectorAll('[data-translate]').forEach(elem => {
                const key = elem.getAttribute('data-translate');
                if (translations[lang][key]) {
                    elem.innerHTML = translations[lang][key];
                }
            });
        }

        // Initialize with French
        changeLanguage('fr');
    </script>
</body>
</html>